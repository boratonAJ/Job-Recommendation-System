{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fields\n",
    "======\n",
    "1. id - The unique identifier for the profile\n",
    "2. careerjunction_za_primary_jobtitle - The most recent job title of the profile\n",
    "3. careerjunction_za_recent_jobtitles - The next job titles after the most recent one (max 2)\n",
    "4. careerjunction_za_historical_jobtitles - All other job titles after recent ones (from the 4th job title)\n",
    "5. careerjunction_za_future_jobtitles - Job titles the seeker would like to have as their next job (ambitions)\n",
    "6. careerjunction_za_employer_names - All employers worked for\n",
    "7. careerjunction_za_skills - All the skills\n",
    "8. careerjunction_za_courses - Titles for education/courses\n",
    " \n",
    "What we want is:-\n",
    "- Any insight into the data that can be extrapolated\n",
    "- If given a profile id, find similar profiles like that one. A combination of similar skills, courses and/or job titles.\n",
    "- If given a profile id, recommend what their next job title(s) could be\n",
    "\n",
    "\n",
    "As the amount of data captured increases, structure of data in the database become unstructured data.\n",
    "From the JSON file, there are over 1000 separate events listed within the file. Each event has different fields, and some of the fields are nested within other fields. \n",
    "This type of data is very hard to store in a regular SQL database.This unstructured data is often stored in a format called JavaScript Object Notation (JSON). \n",
    "JSON is a way to encode data structures like lists and dictionaries to strings that ensures that they are easily readable by machines. Even though JSON starts with the word Javascript, \n",
    "it's actually just a format, and can be read by any language.\n",
    "\n",
    "Python has great JSON support, with the json library. We can both convert lists and dictionaries to JSON, and convert strings to lists and dictionaries. \n",
    "JSON data looks much like a dictionary would in Python, with keys and values stored.\n",
    "\n",
    "In this task, we explored the JSON file using Jupyter notebook, and then import it into Python and work with it using Pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "The data contains information about career post and information about how to match candidate to a particular job post and then make further suggestion \n",
    "about likehood of the post. There are quite a few questions we could answer using the dataset, including:\n",
    "\n",
    "    [1.] What is the total number of the profile ID's' job present?\n",
    "    [2.] What are the most common skills, education, and courses people serach for?\n",
    "    [3.] What are the most common primary job title and recent job titles?\n",
    "    [4.] employer names, future job titles etc.\n",
    "    \n",
    "Since we don't know the structure of the JSON file upfront (as assumption), so we do some exploration to figure it out. This task used Jupyter Notebook for the exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the JSON data\n",
    "\n",
    "The first thing we do is taking a look at the first few lines of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"careerjunction_za_historical_jobtitles\": [\n",
      "      \"Marketer & Technical Liaison\",\n",
      "      \"Quality Assurance Manager Haccp Team Leader\",\n",
      "      \"New Product Developer Technologist\",\n",
      "      \"Food Technologist\",\n",
      "      \"Quality Controller\"\n",
      "    ],\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# path to the data set\n",
    "head ../NumPy/datasets/data_science_extract.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that the JSON data is a list of dictionary, and it is well formatted. \n",
    "We can also see that:\n",
    "    \n",
    "#### \"profile id\", \"careerjunction_za_historical_jobtitles\",\"careerjunction_za_primary_jobtitle\",\n",
    "#### \"careerjunction_za_employer_names\", \"careerjunction_za_skills\", \"careerjunction_za_courses\", \n",
    "#### \"careerjunction_za_recent_jobtitles\", \"careerjunction_za_future_jobtitles\", \n",
    "\n",
    "are top level key, and they are indented three spaces. We get all of the top level keys by using the grep command to print any lines that have three leading spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the data set that the top level keys ae in the header. A list of lists appears to be associated with the data set, and this likely contains each record in the job profile dataset. \n",
    "Each inner list is a record, and the first record appears in the output from the grep command.\n",
    "\n",
    "We print out the full key structure of the JSON file by using grep to print out any lines with 2-6 leading spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us the full key structure associated with data_science_extract.json, and tell us which parts of the JSON file are relevant for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information on the columns\n",
    "\n",
    "Now that we know which key contains information on the columns, we read that information in. \n",
    "We assumed that the JSON file can't fit in memory and we can't just directly read it in using the json library. \n",
    "Instead, we iteratively read it in in a memory-efficient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the column is equal to the total number of profile_id within the dataset 2000\n"
     ]
    }
   ],
   "source": [
    "import json #  json package iteratively parse the json file instead of reading it all in at once\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "filename = \"../NumPy/datasets/data_science_extract.json\"\n",
    "\n",
    "#strs = \"{u'key':u'val'}\"\n",
    "#strs = strs.replace(\"u'\",'\"')\n",
    "#print strs\n",
    "def js_data(filename):\n",
    "   with open(filename, 'r') as f_in:\n",
    "    objects = json.load(f_in, encoding=\"utf-8\")\n",
    "    columns = list(objects)\n",
    "    return columns\n",
    "\n",
    "#https://medium.com/@gis10kwo/converting-nested-json-data-to-csv-using-python-pandas-dc6eddc69175    \n",
    "if __name__ == \"__main__\":\n",
    "    columns = js_data(filename)\n",
    "    #print columns\n",
    "print \"The length of the column is equal to the total number of profile_id within the dataset {}\".format(len(columns))\n",
    "    \n",
    "for row in columns:\n",
    "    selected_row.append(row)\n",
    "#print selected_row[1]\n",
    "column_headers= len(selected_row)\n",
    "\n",
    "all_rows = []\n",
    "for i in selected_row:\n",
    "    all_rows.append(i)\n",
    "#print all_rows[0:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "careerjunction_za_historical_jobtitles []\n",
      "careerjunction_za_primary_jobtitle Social Manager\n",
      "careerjunction_za_skills [u'C# Developer', u'MYSQL', u'PHP', u'javascript', u'CSS3', u'HTML5', u'wordpress', u'AJAX', u'RDBMS', u'Magento', u'C++ Developer', u'JAVA Developer']\n",
      "careerjunction_za_courses [u'Bsc in Computer Systems', u'Higher National Diploma in Information Technology', u'Senior Certificate']\n",
      "careerjunction_za_employer_names [u'Bruce Records Studio', u'Crystal MAP']\n",
      "careerjunction_za_recent_jobtitles [u'Junior Developer']\n",
      "careerjunction_za_future_jobtitles [u'Web Developer', u'Application Developer', u'C# Developer']\n",
      "id 3\n"
     ]
    }
   ],
   "source": [
    "# code for using the id to search the dict values\n",
    "def get_val(dct,key):\n",
    "    for k, v in dct.iteritems():\n",
    "        if key in dct.keys():\n",
    "            print k, v\n",
    "        else :\n",
    "            for d in dct.values():\n",
    "                get_val(d, key)\n",
    "\n",
    "key='id'\n",
    "get_val(selected_row[2],key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "careerjunction_za_courses                 object\n",
       "careerjunction_za_employer_names          object\n",
       "careerjunction_za_future_jobtitles        object\n",
       "careerjunction_za_historical_jobtitles    object\n",
       "careerjunction_za_primary_jobtitle        object\n",
       "careerjunction_za_recent_jobtitles        object\n",
       "careerjunction_za_skills                  object\n",
       "id                                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = pd.io.json.json_normalize(columns)\n",
    "msgs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing list in the row of each column\n",
    "'''\n",
    "for i in selected_row[0]['careerjunction_za_recent_jobtitles']:\n",
    "    if i in selected_row[1]['careerjunction_za_recent_jobtitles']:\n",
    "        print True\n",
    "    else:\n",
    "        print False\n",
    "\n",
    "'''\n",
    "\n",
    "def compare_listcomp(row_x, row_y):\n",
    "    return [i for i, j in zip(row_x, row_y) if i == j]\n",
    "\n",
    "\n",
    "def compare_intersect(row_x, row_y):\n",
    "    return frozenset(row_x).intersection(row_y)\n",
    "\n",
    "\n",
    "compare_listcomp(selected_row[0]['careerjunction_za_recent_jobtitles'], selected_row[1]['careerjunction_za_recent_jobtitles'])\n",
    "compare_intersect(selected_row[0]['careerjunction_za_recent_jobtitles'], selected_row[1]['careerjunction_za_recent_jobtitles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Food Technologist', u'Product Specialist Microbiology']\n",
      "[u'Senior Developer', u'Senior Developer']\n",
      "([], [u'Food Technologist', u'Product Specialist Microbiology'])\n"
     ]
    }
   ],
   "source": [
    "# Given profile ID\n",
    "\n",
    "def profile_id(selected_row):\n",
    "    column_headers = selected_row\n",
    "    return column_headers\n",
    "\n",
    "print (profile_id(selected_row[0]['careerjunction_za_recent_jobtitles']))\n",
    "print (profile_id(selected_row[1]['careerjunction_za_recent_jobtitles']))\n",
    "\n",
    "def look_up_similar(selected_row1, selected_row2):\n",
    "    get_similar = []\n",
    "    get_not_similar = []\n",
    "    cnt = 0\n",
    "    for i in selected_row1:\n",
    "        if i in selected_row2:\n",
    "            get_similar.append(i)\n",
    "            cnt = +1\n",
    "        else:\n",
    "            get_not_similar.append(i)\n",
    "            cnt = +1\n",
    "    return get_similar, get_not_similar\n",
    "\n",
    "print look_up_similar(selected_row[0]['careerjunction_za_recent_jobtitles'],selected_row[1]['careerjunction_za_recent_jobtitles'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-198-aa165885c360>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-198-aa165885c360>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    return rows\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "#separate and group all dictionary to list\n",
    "import ijson\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Comparison\n",
    "Here I compare each of the dictionary in the dataset to find the profile similiarity using the profile id to compare to the recent jobtiltle, career skills, course/education list within the dictionary \n",
    "and I then use that to determine the jobtitle similarities.\n",
    "\n",
    "#### A simple approach:\n",
    "\n",
    "I make a new dict with the id's as key; lets call it source\n",
    "the value of each source is is also a dict of the other ids (you are building a matrix); lets call it target\n",
    "fill the count for source id at the target id with a counter of comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'careerjunction_za_courses': [u'Advanced Diploma In Computer Science'],\n",
       " u'careerjunction_za_primary_jobtitle': u'Database Developer Application Programmer',\n",
       " u'careerjunction_za_recent_jobtitles': [u'Programmer Technician'],\n",
       " u'careerjunction_za_skills': [u'Programming', u'Technical Support'],\n",
       " u'id': 4}"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_source(dict_l):\n",
    "    good_columns = [\"id\",\"careerjunction_za_courses\", \"careerjunction_za_skills\", \n",
    "                \"careerjunction_za_recent_jobtitles\",\"careerjunction_za_primary_jobtitle\"]\n",
    "    n = {}\n",
    "    k = 'id'\n",
    "    for k,v in dict_l.items():\n",
    "        for i in good_columns:\n",
    "            if i==k:\n",
    "                n[k] = v\n",
    "    return n\n",
    "new_source(all_rows[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all values from all_rows list dictionary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-596-8f1499817d8e>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-596-8f1499817d8e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    return count_lst_id = [item for value in count_lst_id for item in literal_eval(value)]\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# extracting and making the list from the all_rows\n",
    "from ast import literal_eval\n",
    "def extract_values(count_lst_id):\n",
    "    return count_lst_id = [item for value in count_lst_id for item in literal_eval(value)]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "value_lst_count0 = extract_values(all_rows[0])\n",
    "value_lst_count1 = extract_values(all_rows[1])\n",
    "value_lst_count2 = extract_values(all_rows[2])\n",
    "value_lst_count3 = extract_values(all_rows[3])\n",
    "value_lst_count5 = extract_values(all_rows[4])\n",
    "value_lst_count6 = extract_values(all_rows[6])\n",
    "\n",
    "\n",
    "value_lst_count0 = extract_values(all_rows[0])\n",
    "\n",
    "print map(str,value_lst_count0)\n",
    "\n",
    "def extract_dict_keys(dict_keys):\n",
    "    return map(str,dict_keys.keys())\n",
    "\n",
    "dict_keys = extract_dict_keys(all_rows[3]) # remove the u' unicode\n",
    "\n",
    "#print dict_keys\n",
    "#print map(str, dict_keys)\n",
    "\n",
    "def subsequence_counts_2(sequences):\n",
    "    counts = Counter()\n",
    "    for sequence in sequences:\n",
    "        input = \"\".join(sequence)\n",
    "        for j in range(1,len(input)+1):\n",
    "    #this involves copying across the whole contents of counts into the new object.\n",
    "            counts.update(input[i:i+j] for i in range(len(input)-(j-1)))\n",
    "    return counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'careerjunction_za_courses',\n",
       " ':',\n",
       " [u'B.Econ', u'Grade 12/Matric'],\n",
       " '->',\n",
       " [u'Bsc in Computer Systems',\n",
       "  u'Higher National Diploma in Information Technology',\n",
       "  u'Senior Certificate'])"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_dict(dict1,dict2):\n",
    "    diffkeys = [k for k in dict1 if dict1[k] != dict2[k]]\n",
    "    for k in diffkeys:\n",
    "        return k, ':', dict1[k], '->', dict2[k]\n",
    "\n",
    "compare_dict(new_source(all_rows[1]),new_source(all_rows[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"careerjunction_za_courses\": [\"Bsc in Computer Systems\", \"Higher National Diploma in Information Technology\", \"Senior Certificate\"], \"careerjunction_za_skills\": [\"C# Developer\", \"MYSQL\", \"PHP\", \"javascript\", \"CSS3\", \"HTML5\", \"wordpress\", \"AJAX\", \"RDBMS\", \"Magento\", \"C++ Developer\", \"JAVA Developer\"], \"careerjunction_za_primary_jobtitle\": \"Social Manager\", \"id\": 3, \"careerjunction_za_recent_jobtitles\": [\"Junior Developer\"]}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codereview.stackexchange.com/questions/108443/extract-data-from-large-json-and-find-frequency-of-contiguous-sub-lists\n",
    "I have been writing some code (see component parts here and here) that:\n",
    "\n",
    "Takes a very large JSON (15GB gzipped, ~10million records)\n",
    "Extracts the relevant parts of the JSON into a list of lists\n",
    "Creates a list of all contiguous n-gram sub-lists found in the array\n",
    "Creates a counter to count the frequency of each n-gram\n",
    "Output the Counter showing the most common occurrences\n",
    "When I run the complete function on the full dataset, I get out of memory errors.\n",
    "\n",
    "Please help me optimise this code. Am I just looking for too many sub-list combinations?\n",
    "\n",
    "I was thinking of possibly chunking up the JSON, processing in parallel and then combining the counters at the end, \n",
    "but I have no idea how to implement parallel processing in IPython 2.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015540122985839844"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding most common contiguous sub-lists in an array of lists\n",
    "# Objective: Given a set of sequences ( eg: step1->step2->step3, step1->step3->step5) ) \n",
    "# arranged in an array of lists, count the number of times every contiguous sub-lists occur\n",
    "# https://codereview.stackexchange.com/questions/108052/finding-most-common-contiguous-sub-lists-in-an-array-of-lists\n",
    "import random\n",
    "import string\n",
    "from collections import Counter\n",
    "from timeit import timeit\n",
    "\n",
    "def subsequence_counts_2(sequences):\n",
    "    counts = Counter()\n",
    "    for sequence in sequences:\n",
    "        input = \"\".join(sequence)\n",
    "        for j in range(1,len(input)+1):\n",
    "    #this involves copying across the whole contents of counts into the new object.\n",
    "            counts.update(input[i:i+j] for i in range(len(input)-(j-1)))\n",
    "    return counts\n",
    "\n",
    "def test_data(n, m, choices):\n",
    "    \"\"\"Return a list of n lists of m items chosen randomly from choices.\"\"\"\n",
    "    return [[random.choice(choices) for _ in range(m)] for _ in range(n)]\n",
    "\n",
    "#subsequence_counts_2(data)\n",
    "data = test_data(10, 10, string.ascii_uppercase)\n",
    "\n",
    "timeit(lambda:subsequence_counts_2(data), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10197997093200684"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"favorited\": false, \"contributors\": null}\n",
      "{u'favorited': False, u'contributors': None}\n",
      "{\"favorited\": false, \"contributors\": null}\n"
     ]
    }
   ],
   "source": [
    "json_string = '{\"favorited\": false, \"contributors\": null}'\n",
    "print json_string\n",
    "value = json.loads(json_string)\n",
    "print value\n",
    "json_dump = json.dumps(value)\n",
    "print json_dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key2': 'value4', 'key1': 'value3'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
